{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02cc7da-a36c-48af-a052-22a5d8c695cc",
   "metadata": {},
   "source": [
    "This file will load, clean, process, and wrangle data from SubstanceHarmsData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1235e65-d2a8-4c70-aaa1-941e62d972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, import the pertinent libraries/packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35ca42-cd77-4fc9-9571-ee63c8adef0b",
   "metadata": {},
   "source": [
    "### SubstanceHarmsData at a glance\n",
    "Our dataset has aggreggate/disaggregate columns with some processed data incl. by age and by sex. To get the overall numbers, choose < specific_measure == 'overall numbers'>. Using pandas to select relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "193a816c-b7ee-4f50-8e6f-ca80c0dad0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Substance, Source, Type of Event, Region]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Substance, Source, Type of Event, Region]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhysh\\AppData\\Local\\Temp/ipykernel_8416/494812722.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df2 = ( df1\n",
      "C:\\Users\\rhysh\\AppData\\Local\\Temp/ipykernel_8416/494812722.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df2 = ( df1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "our csv contains aggregate/disaggregate columns. Since we'll be doing our own processing, we'll\n",
    "drop these and focus on our own aggregates/processing\n",
    "\"\"\"\n",
    "\n",
    "def load_process_data(path_to_file):\n",
    "    \n",
    "    # Load Data into df1\n",
    "    df1 = (\n",
    "        pd.read_csv(path_to_file) #load data\n",
    "        .dropna(axis=1,how='all') #drop columns with all NaN values\n",
    "        .dropna(subset=['Substance','Source', 'Type_Event','Specific_Measure','Region','Unit','Value']) #drop rows with missing pertinent values\n",
    "        .rename(columns={\"Specific_Measure\":\"Specific Measure\",\"Type_Event\":\"Type of Event\"}) #rename some columns\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    drop_list = [\"PRUID\",\"Year_Quarter\",\"Time_Period\",\"Value\",\"Aggregator\",\"Unit\",\"Specific Measure\",\"Disaggregator\"]\n",
    "    \n",
    "    # drop columns + add new ones\n",
    "    df2 = ( df1\n",
    "        [df1[\"Specific Measure\"]==\"Overall numbers\"]\n",
    "        [df1[\"Unit\"] == \"Numbers\"]\n",
    "        .drop(drop_list,1)\n",
    "    )\n",
    "    \n",
    "    print(df2.head())\n",
    "    \n",
    "    return df2\n",
    "\n",
    "# initial thoughts: Type of Event is highly correlated with Source and Substance\n",
    "#load_process_data('../../data/raw/SubstanceHarmsData.csv')\n",
    "\n",
    "\n",
    "df2 = load_process_data('../../data/raw/SubstanceHarmsData.csv')\n",
    "print(df2.head(15))\n",
    "#df2_profile = ProfileReport(df2).to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bbd64-8b20-407f-90bf-193794079ef1",
   "metadata": {},
   "source": [
    "### Data Analysis Pipeline\n",
    "1. Load Date:\n",
    "    Check file type (.csv);\n",
    "    Delimiters (commas);\n",
    "    Skip rows & columns\n",
    "2. Clean Data:\n",
    "    Remove unused columns (PRUID, Year_Quarter, Value);\n",
    "    Deal w incorrect data;\n",
    "    Deal w missing data\n",
    "3. Process Data:\n",
    "    Create new columns (combinations, aggregates);\n",
    "    Find + Replace operation;\n",
    "    Other substitutions\n",
    "4. Wrangle Data:\n",
    "    Restructure format\n",
    "5. EDA (Task 3)\n",
    "6. Data Analysis (Task 4)\n",
    "7. Export reports/analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea9cb7-bfe3-40b2-a883-0c1ee92719b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
